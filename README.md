# Thirukkural_gpt
This project demonstrates how to fine-tune the **LLaMA-2-7B Chat** model using **LoRA** (Low-Rank Adaptation) and perform text generation tasks using Hugging Face's `transformers` library.

## Features
- Fine-tune the **LLaMA-2** model on custom text data.
- Quantization support with 4-bit precision to optimize resource usage.
- Text generation using LoRA-enhanced models.
- Real-time text input for interactive model inference.

## Requirements

Ensure that you have the required Python packages installed by running the following command:

```bash
pip install -r requirements.txt
